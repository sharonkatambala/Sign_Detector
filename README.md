# ğŸ¤Ÿ SignWait - Real-time ASL Detector

A modern web application that uses computer vision and AI to detect American Sign Language (ASL) fingerspelling in real-time, right in your browser.

![SignWait Demo](https://img.shields.io/badge/Status-Active-success)
![React](https://img.shields.io/badge/React-18.3-blue)
![TypeScript](https://img.shields.io/badge/TypeScript-5.6-blue)
![MediaPipe](https://img.shields.io/badge/MediaPipe-Hand%20Tracking-orange)

## âœ¨ Features

- **ğŸ¥ Real-time Detection**: Uses MediaPipe and TensorFlow.js to track hand landmarks and classify signs
- **ğŸ”¤ Smart Autocomplete**: Suggests words based on fingerspelled characters
- **ğŸ”Š Text-to-Speech**: Pronounce your typed sentences with a single click
- **ğŸ”’ Privacy Focused**: All processing happens locally in your browserâ€”no video is sent to the cloud
- **ğŸ¨ Modern UI**: Beautiful glassmorphism design with dark theme and smooth animations

## ğŸš€ Getting Started

### Prerequisites

- Node.js (v16 or higher)
- A webcam
- Modern web browser (Chrome, Edge, or Firefox recommended)

### Installation

1. **Clone the repository**:
   ```bash
   git clone https://github.com/sharonkatambala/Sign_Detector.git
   cd Sign_Detector
   ```

2. **Install dependencies**:
   ```bash
   npm install
   ```

3. **Start the development server**:
   ```bash
   npm run dev
   ```

4. **Open your browser** and navigate to the URL shown (usually `http://localhost:5173`)

5. **Allow camera access** when prompted

## ğŸ“– Usage

1. **Sign**: Hold your hand in front of the camera
2. **Type**: Signs held steadily will be added to the transcript
3. **Select**: Click a word suggestion to auto-complete your thought
4. **Speak**: Click the Play button to hear your text spoken aloud

### Supported Signs (Demo)

Currently supports basic ASL signs:
- âœŠ **A/S** - Fist (thumb position varies)
- âœ‹ **B** - Open hand
- â˜ï¸ **D** - Pointing finger
- ğŸ¤ **V** - Peace sign
- ğŸ¤™ **Y** - Shaka sign
- ğŸ‘Œ **L** - L shape
- ğŸ¤˜ **I** - Pinky up
- ğŸ–– **W** - Three fingers extended
- ğŸ¤Ÿ **I Love You** sign

## ğŸ› ï¸ Technology Stack

- **Frontend**: React 18.3 + TypeScript
- **Build Tool**: Vite 7.3
- **Computer Vision**: MediaPipe Hand Landmarker
- **UI**: Custom CSS with Glassmorphism
- **Speech**: Web Speech API
- **Icons**: Lucide React

## ğŸ“ Project Structure

```
Sign_Detector/
â”œâ”€â”€ src/
â”‚   â”œâ”€â”€ App.tsx              # Main application component
â”‚   â”œâ”€â”€ index.css            # Global styles and design system
â”‚   â”œâ”€â”€ components/
â”‚   â”‚   â””â”€â”€ CameraView.tsx   # Webcam + hand detection
â”‚   â””â”€â”€ lib/
â”‚       â”œâ”€â”€ handDetector.ts  # MediaPipe wrapper
â”‚       â”œâ”€â”€ classifier.ts    # Sign recognition logic
â”‚       â””â”€â”€ dictionary.ts    # Autocomplete engine
â”œâ”€â”€ public/
â”‚   â””â”€â”€ debug.html          # Diagnostic page
â”œâ”€â”€ index.html
â”œâ”€â”€ package.json
â””â”€â”€ README.md
```

## ğŸ¯ How It Works

1. **Hand Detection**: MediaPipe's Hand Landmarker detects 21 keypoints on your hand in 3D space
2. **Feature Extraction**: The app analyzes finger positions (extended/curled) and hand shape
3. **Classification**: Geometric heuristics map hand poses to ASL letters
4. **Smoothing**: Predictions are smoothed using a moving window and confidence threshold
5. **Autocomplete**: As letters are typed, the dictionary suggests matching words
6. **Speech**: Selected text is pronounced using the browser's native TTS engine

## ğŸ”§ Improving Accuracy

The current classifier uses **rule-based heuristics**. For production-grade A-Z recognition:

### Option 1: Train a Custom Model
1. Collect landmark data for all 26 letters
2. Train an MLP or Random Forest in Python
3. Export to TensorFlow.js
4. Load in `classifier.ts`

### Option 2: Use an Existing Model
- Integrate pre-trained ASL recognition models
- Fine-tune on your own data
- Use transfer learning from existing hand pose datasets

## ğŸ› Troubleshooting

### White/Blank Screen
1. Open browser console (F12) and check for errors
2. Hard refresh: `Ctrl + Shift + R` (Windows) or `Cmd + Shift + R` (Mac)
3. Ensure camera permissions are granted

### Model Loading Issues
- Check your internet connection (model downloads from Google CDN)
- Try the debug page: `http://localhost:5173/debug.html`

### Low FPS or Lag
- Close other tabs/applications
- Lower video resolution in browser settings
- Use a device with better GPU support

## ğŸ¤ Contributing

Contributions are welcome! Here are some ways you can help:

- ğŸ› Report bugs and issues
- ğŸ’¡ Suggest new features
- ğŸ“ Improve documentation
- ğŸ¨ Enhance the UI/UX
- ğŸ§  Train better models for A-Z recognition
- ğŸŒ Add support for other sign languages

## ğŸ“„ License

This project is open source and available under the [MIT License](LICENSE).

## ğŸ™ Acknowledgments

- [MediaPipe](https://mediapipe.dev/) for the Hand Landmarker model
- [TensorFlow.js](https://www.tensorflow.org/js) for browser-based ML
- Google for hosting the pre-trained models

## ğŸ“ Contact

Created by [Sharon Katambala](https://github.com/sharonkatambala)

---

â­ **Star this repo** if you find it helpful!
